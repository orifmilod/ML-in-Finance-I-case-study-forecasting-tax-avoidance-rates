{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Instructions: Panel Data Modeling with Machine Learning Models\n",
    "\n",
    "**Objective:**\n",
    "The goal of this exercise is to practice panel data modeling skills using three machine learning models (Random Forest, Single Decision Tree, and Linear Regression with Elastic Net) that have not been utilized in the project so far. Completing the entire task or a significant portion during the class will earn you an additional 7 points (above what is outlined in the syllabus) towards your final grade.\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. **GitHub Setup:**\n",
    "   - If you haven't done so already, [create](https://github.com/join) a GitHub account.\n",
    "   - [Download](https://desktop.github.com) and [configure](https://docs.github.com/en/desktop/configuring-and-customizing-github-desktop/configuring-basic-settings-in-github-desktop) GitHub Desktop on your laptop. (Here you can find nice intro to the GitHub Dekstop app: [link](https://joshuadull.github.io/GitHub-Desktop/02-getting-started/index.html)). If you prefare git command line usage you can go with this [instruction](https://github.com/michaelwozniak/ml2_tools?tab=readme-ov-file#git).\n",
    "2. **Repository Forking:**\n",
    "   - [Fork](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/working-with-forks/fork-a-repo) the following repository to your projects: [https://github.com/michaelwozniak/ML-in-Finance-I-case-study-forecasting-tax-avoidance-rates](https://github.com/michaelwozniak/ML-in-Finance-I-case-study-forecasting-tax-avoidance-rates)\n",
    "\n",
    "3. **Repository Cloning:**\n",
    "   - [Clone](https://docs.github.com/en/desktop/adding-and-cloning-repositories/cloning-a-repository-from-github-to-github-desktop) the forked repository to your local computer using GitHub Desktop.\n",
    "\n",
    "4. **Notebook Exploration:**\n",
    "   - Open the file `notebooks/10.exercise.ipynb` to begin the ML tasks.\n",
    "\n",
    "5. **Model Creation:**\n",
    "\n",
    "   In the file `notebooks/10.exercise.ipynb`:\n",
    "   - Create the following models:\n",
    "      1. Random Forest ([RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html))\n",
    "      2. Decision Tree ([DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html))\n",
    "      3. Linear Regression with Elastic Net ([ElasticNet](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html))\n",
    "   \n",
    "   Follow a similar process to the models presented in class (e.g., KNN - `notebooks/07.knn-model.ipynb`):\n",
    "      - Load the prepared training data.\n",
    "      - Perform feature engineering if deemed necessary (note: these three models do not require data standardization, unlike SVM and KNN).\n",
    "      - Conduct feature selection.\n",
    "      - Perform hyperparameter tuning.\n",
    "      - Identify a local champion for each model class (the best model for RF, DT, Elastic Net).\n",
    "      - Save local champions to a pickle file.\n",
    "\n",
    "6. **Model Evaluation:**\n",
    "   - In the notebook `notebooks/09.final-comparison-and-summary.ipynb`, load the models you created and check if they outperform the previously used models.\n",
    "\n",
    "7. **Version Control:**\n",
    "   - At the end of the class, even if the tasks are incomplete, [commit](https://docs.github.com/en/desktop/making-changes-in-a-branch/committing-and-reviewing-changes-to-your-project-in-github-desktop) your changes using GitHub Desktop.\n",
    "   - [Push](https://docs.github.com/en/desktop/making-changes-in-a-branch/pushing-changes-to-github-from-github-desktop) your changes to your remote GitHub repository.\n",
    "\n",
    "8. **Submission:**\n",
    "   - Send me the link to your GitHub project (my email: *mj.wozniak9@uw.edu.pl*).\n",
    "\n",
    "Good luck with the exercise! If you have any questions, feel free to ask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I hate dependency management\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./train_fe.csv\", index_col=0)\n",
    "df_test = pd.read_csv(\"./test_fe.csv\", index_col=0)\n",
    "\n",
    "df = pd.concat([df_train, df_test], axis=0)\n",
    "\n",
    "fr = pd.read_excel(\"feature_ranking.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "\n",
    "We have to standardize our variables. We will use range standardization (Min Max Scaler) because we have got dummies! We gave every variable a chance to have the same impact on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "[1. 1. 1.]\n",
      "[2.01600000e+03 0.00000000e+00 8.73839499e-04 1.00000000e+00]\n",
      "[2.01600000e+03 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 5.16991643e-01 1.00000000e+00 0.00000000e+00]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['etr_y_past',\n",
       " 'etr_y_ma',\n",
       " 'txt',\n",
       " 'diff',\n",
       " 'ni',\n",
       " 'pi',\n",
       " 'intant',\n",
       " 'intant_sqrt',\n",
       " 'ta',\n",
       " 'revenue']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\n",
    "    \"rok\",\n",
    "    \"ta\",\n",
    "    \"txt\",\n",
    "    \"pi\",\n",
    "    \"str\",\n",
    "    \"xrd\",\n",
    "    \"ni\",\n",
    "    \"ppent\",\n",
    "    \"intant\",\n",
    "    \"dlc\",\n",
    "    \"dltt\",\n",
    "    \"capex\",\n",
    "    \"revenue\",\n",
    "    \"cce\",\n",
    "    \"adv\",\n",
    "    \"etr\",\n",
    "    \"diff\",\n",
    "    \"roa\",\n",
    "    \"lev\",\n",
    "    \"intan\",\n",
    "    \"rd\",\n",
    "    \"ppe\",\n",
    "    \"sale\",\n",
    "    \"cash_holdings\",\n",
    "    \"adv_expenditure\",\n",
    "    \"capex2\",\n",
    "    \"cfc\",\n",
    "    \"dta\",\n",
    "    \"capex2_scaled\",\n",
    "    \"y_v2x_polyarchy\",\n",
    "    \"y_e_p_polity\",\n",
    "    \"y_BR_Democracy\",\n",
    "    \"WB_GDPgrowth\",\n",
    "    \"WB_GDPpc\",\n",
    "    \"WB_Inflation\",\n",
    "    \"rr_per_country\",\n",
    "    \"rr_per_sector\",\n",
    "    \"sektor_consumer discretionary\",\n",
    "    \"sektor_consumer staples\",\n",
    "    \"sektor_energy\",\n",
    "    \"sektor_health care\",\n",
    "    \"sektor_industrials\",\n",
    "    \"sektor_materials\",\n",
    "    \"sektor_real estate\",\n",
    "    \"sektor_technology\",\n",
    "    \"sektor_utilities\",\n",
    "    \"gielda_2\",\n",
    "    \"gielda_3\",\n",
    "    \"gielda_4\",\n",
    "    \"gielda_5\",\n",
    "    \"ta_log\",\n",
    "    \"txt_cat_(-63.011, -34.811]\",\n",
    "    \"txt_cat_(-34.811, 0.488]\",\n",
    "    \"txt_cat_(0.488, 24.415]\",\n",
    "    \"txt_cat_(24.415, 25.05]\",\n",
    "    \"txt_cat_(25.05, 308.55]\",\n",
    "    \"txt_cat_(308.55, 327.531]\",\n",
    "    \"txt_cat_(327.531, inf]\",\n",
    "    \"pi_cat_(-8975.0, -1.523]\",\n",
    "    \"pi_cat_(-1.523, 157.119]\",\n",
    "    \"pi_cat_(157.119, 465.9]\",\n",
    "    \"pi_cat_(465.9, 7875.5]\",\n",
    "    \"pi_cat_(7875.5, 8108.5]\",\n",
    "    \"pi_cat_(8108.5, inf]\",\n",
    "    \"str_cat_(0.0875, 0.192]\",\n",
    "    \"str_cat_(0.192, 0.28]\",\n",
    "    \"str_cat_(0.28, inf]\",\n",
    "    \"xrd_exists\",\n",
    "    \"ni_profit\",\n",
    "    \"ni_profit_20000\",\n",
    "    \"ppent_sqrt\",\n",
    "    \"intant_sqrt\",\n",
    "    \"dlc_cat_(42.262, 176.129]\",\n",
    "    \"dlc_cat_(176.129, 200.9]\",\n",
    "    \"dlc_cat_(200.9, inf]\",\n",
    "    \"dltt_cat_(39.38, 327.85]\",\n",
    "    \"dltt_cat_(327.85, 876.617]\",\n",
    "    \"dltt_cat_(876.617, inf]\",\n",
    "    \"capex_cat_(7.447, 79.55]\",\n",
    "    \"capex_cat_(79.55, 5451.0]\",\n",
    "    \"capex_cat_(5451.0, inf]\",\n",
    "    \"revenue_cat_(0.174, 1248.817]\",\n",
    "    \"revenue_cat_(1248.817, 4233.587]\",\n",
    "    \"revenue_cat_(4233.587, inf]\",\n",
    "    \"cce_cat_(5.619, 63.321]\",\n",
    "    \"cce_cat_(63.321, inf]\",\n",
    "    \"adv_cat_(0.3, 874.5]\",\n",
    "    \"adv_cat_(874.5, inf]\",\n",
    "    \"diff_positive\",\n",
    "    \"roa_clip\",\n",
    "    \"lev_sqrt\",\n",
    "    \"intan_pow2\",\n",
    "    \"rd_sqrt\",\n",
    "    \"ppe_clip\",\n",
    "    \"cash_holdings_sqrt\",\n",
    "    \"adv_expenditure_positive\",\n",
    "    \"diff_dta\",\n",
    "    \"cfc_dta\",\n",
    "    \"etr_y_past\",\n",
    "    \"etr_y_ma\",\n",
    "    \"diff_ma\",\n",
    "    \"roa_ma\",\n",
    "    \"lev_ma\",\n",
    "    \"intan_ma\",\n",
    "    \"ppe_ma\",\n",
    "    \"sale_ma\",\n",
    "    \"cash_holdings_ma\",\n",
    "    \"roa_past\",\n",
    "    \"lev_past\",\n",
    "    \"intan_past\",\n",
    "    \"ppe_past\",\n",
    "    \"sale_past\",\n",
    "    \"cash_holdings_past\",\n",
    "]\n",
    "\n",
    "standardization = []\n",
    "not_standardization = []\n",
    "for i in columns:\n",
    "    if df[i].nunique() > 2:\n",
    "        standardization.append(i)\n",
    "    else:\n",
    "        not_standardization.append(i)\n",
    "standardization.remove(\"etr\")\n",
    "standardization.append(\"y_e_p_polity\")\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df[standardization])\n",
    "df[standardization] = scaler.transform(df[standardization])\n",
    "print(df[columns].describe().T[\"min\"].unique())\n",
    "print(df[columns].describe().T[\"max\"].unique())\n",
    "\n",
    "var = fr.mi_score.sort_values(ascending=False).index.tolist()[0:10]\n",
    "df.shape[0] ** (0.5)\n",
    "\n",
    "mse = make_scorer(mean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omilod/Desktop/projects/temp/env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "540 fits failed out of a total of 1080.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "540 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/omilod/Desktop/projects/temp/env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/omilod/Desktop/projects/temp/env/lib/python3.9/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/omilod/Desktop/projects/temp/env/lib/python3.9/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/omilod/Desktop/projects/temp/env/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/omilod/Desktop/projects/temp/env/lib/python3.9/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.04249529 0.10929904 0.11649173\n",
      " 0.05847413 0.11778924 0.11928071 0.07192646 0.12452262 0.13056816\n",
      " 0.07533797 0.10750004 0.12063409 0.07623633 0.1224801  0.12910881\n",
      " 0.07476084 0.12795413 0.129631   0.10013686 0.12754329 0.13762958\n",
      " 0.08999551 0.13445284 0.14118746 0.11969475 0.13181903 0.14415536\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.10072844 0.1376193  0.13028317\n",
      " 0.10826756 0.13356543 0.13471947 0.10245782 0.13793669 0.13695603\n",
      " 0.11223437 0.13576129 0.14114715 0.10283297 0.13330879 0.14089759\n",
      " 0.10075208 0.13983608 0.14583615 0.124175   0.14086884 0.14302779\n",
      " 0.12821772 0.14028739 0.14537848 0.12047656 0.14663271 0.14725091\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.02796789 0.10444168 0.11660743\n",
      " 0.073283   0.11653264 0.11969043 0.07576406 0.12827128 0.12612553\n",
      " 0.07457805 0.11710419 0.12785515 0.08673312 0.11712123 0.13375394\n",
      " 0.07452538 0.13297542 0.13616937 0.10583317 0.13219028 0.14097393\n",
      " 0.10681907 0.14275581 0.14175539 0.10135163 0.13926456 0.14040638\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.0464261  0.10824201 0.11052332\n",
      " 0.06273946 0.11676793 0.11871882 0.08684072 0.12103332 0.12675128\n",
      " 0.07470977 0.11978968 0.1260493  0.10777883 0.1161602  0.12708376\n",
      " 0.1011522  0.1296564  0.13754766 0.11095817 0.13117872 0.13939044\n",
      " 0.09521775 0.13283593 0.13629506 0.10839585 0.13146116 0.13624005]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for RandomForest: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Best score for RandomForest: 0.14725091287694575\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=10, max_features=&#x27;sqrt&#x27;, min_samples_leaf=4,\n",
       "                      min_samples_split=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=10, max_features=&#x27;sqrt&#x27;, min_samples_leaf=4,\n",
       "                      min_samples_split=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=10, max_features='sqrt', min_samples_leaf=4,\n",
       "                      min_samples_split=10)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the parameter grid for RandomForest\n",
    "param_grid_random_forest = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object for RandomForest\n",
    "# Random forest default criterion is mse, so no need to pass it as a parameter\n",
    "grid_search_rf = GridSearchCV(RandomForestRegressor(), param_grid_random_forest, cv=5)\n",
    "grid_search_rf.fit(df.loc[:, var].values, df.loc[:, \"etr\"].values.ravel())\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters for RandomForest:\", grid_search_rf.best_params_)\n",
    "print(\"Best score for RandomForest:\", grid_search_rf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'max_depth': 2, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best score:  -0.019032479638322383\n"
     ]
    }
   ],
   "source": [
    "reg = DecisionTreeRegressor()\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [None, 2, 3, 4, 5],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'min_samples_leaf': [1, 2, 3]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=reg, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(df.loc[:, var].values, df.loc[:, \"etr\"].values.ravel())\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for ElasticNet: {'alpha': 0.1, 'l1_ratio': 0.5}\n",
      "Best score for ElasticNet: 0.02505182932311576\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for ElasticNet\n",
    "param_grid_elastic_net = {\n",
    "    'alpha': [0.1, 1, 10],\n",
    "    'l1_ratio': [0.1, 0.5, 0.9]\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object for ElasticNet\n",
    "grid_search_en = GridSearchCV(ElasticNet(), param_grid_elastic_net, cv=5)\n",
    "grid_search_en.fit(df.loc[:, var].values, df.loc[:, \"etr\"].values.ravel())\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters for ElasticNet:\", grid_search_en.best_params_)\n",
    "print(\"Best score for ElasticNet:\", grid_search_en.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bff0f7c864331389fa2ce0c5d534e26d0bfdbc8f9c927a5938dc8a191fde6d96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
